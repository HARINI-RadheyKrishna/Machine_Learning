{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HARINI-RadheyKrishna/Machine_Learning/blob/master/Readign_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EE 599 Reading Assignment \\# 2:\n"
      ],
      "metadata": {
        "id": "JA0rETRQZBON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1: (1 Point)\n",
        "\n",
        "**Disallowed** list:\n",
        "- You **MAY NOT** collaborate with anyone else on this assignment. This means you cannot talk to anyone else about the assignment until after deadline.\n",
        "- You **MAY NOT** use ChatGPT and services like that\n",
        "\n",
        "**Allowed** list:\n",
        "- Notes including any slides from the class\n",
        "- The textbooks\n",
        "- The given paper"
      ],
      "metadata": {
        "id": "s-HWWv6kaxrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A1:\n",
        "\n",
        "I affirm I have read these exam rules and will follow them. Failure to do so may subject me to sanctions including an F in the course.\n",
        "\n",
        "**Type your full name to affirm you have read the above statement:**\n"
      ],
      "metadata": {
        "id": "Pz0uD-nHbHuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Harini Thirunavukkarasu"
      ],
      "metadata": {
        "id": "PldisnWYGFdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2 (99 Points):\n",
        "\n",
        "Use this [paper](https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf) as your guideline on how to read papers in general.\n",
        "\n",
        "For this assignment, please write a summary of this paper:\n",
        "\n",
        "\"In-Datacenter Performance Analysis of a Tensor Processing Unit\"\n",
        "\n",
        "Complete info:\n",
        "\n",
        "Jouppi, Norman P., Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates et al. \"In-datacenter performance analysis of a tensor processing unit.\" In Proceedings of the 44th annual international symposium on computer architecture, pp. 1-12. 2017.\n",
        "\n",
        "You can download it from [here](https://arxiv.org/pdf/1704.04760.pdf?mod=article_inline)."
      ],
      "metadata": {
        "id": "IzxAsb2ErvaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## Q2.1 Summary (19 Points):\n",
        "\n",
        "Summarize the main objectives and contributions of the paper."
      ],
      "metadata": {
        "id": "XzNWLVCLbcjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A2.1:\n",
        "\n",
        "**Objectives:**\n",
        "\n",
        "The  \n",
        "\n",
        "\n",
        "**Contributions:**\n",
        "\n"
      ],
      "metadata": {
        "id": "0j5A4_Zfbpra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.2 Comprehension (10 Points):\n",
        "- What is a Tensor Processing Unit (TPU) and how does it differ from traditional CPUs and GPUs in terms of design and purpose?\n",
        "- Why is there a need for specialized hardware like TPUs in modern data centers?"
      ],
      "metadata": {
        "id": "IE2n5UQHbuZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A2.2:\n",
        "\n",
        "A Tensor Processing Unit is a customized ASIC which is deployed in daracenters to accelerate the inference phase of neural networks.\n",
        "\n",
        "GPUs and CPUs are general purpose processors designed for a wide range of tasks and not for dedicated purposes. GPUs exploit the parallelism in the instruction for improved performance and throughput for huge data-driven applications like handling convolutions, image processing, etc. CPUs are on the other hand used for small data-driven applications like an ordinary addition or multiplication computation purposes.\n",
        "\n",
        "**Differences between TPU and (CPU and GPU)**\n",
        "\n",
        "The major difference lies in the implementation of the hardware architecture among the 3 different types of processors.\n",
        "\n",
        "TPUs do not have extensive hardware units like branch predictors, out-of-order executing pipeline, multi-threaded core, multiple processors, pre-fetch buffers etc., whereas CPUs and GPUs have specialized hardware implemented onto their processor for efficient handling of a wide range of tasks.\n",
        "\n",
        "TPUs are more specifically involved only for tasks involving a large number of matrix multiplications and tensor operations thereby speeding up the response time for NNs. CPUs and GPUs are not domain specific instead for generalized use cases.\n",
        "\n",
        "**Why are specialized hardwares like TPUs needed:**\n",
        "\n",
        "1. Energy efficiency:\n",
        "\n",
        "TPUs are specifically designed to meet the growing demands for handling convolutional and deep neural networks which involves a lot of matrix multiplications. Instead of running the applications on a more generalized hardware like GPUs and CPUs, running the models on TPUs provide increased energy efficiency as all the processing units are populated and utilised efficiently for the matrix multiplication.\n",
        "\n",
        "The units like branch predictors, out-of-order pipelines etc do not find good use in this domain and if we are to use GPUs and TPUs we are underutilizing them and boosting the energy consumption due to those units being turned on almost all of the time. But the lack of these units in TPUs will lead to optimized power consumption and hence save energy ultimately.\n",
        "\n",
        "2. Cost efficient:\n",
        "\n",
        "For specific workloads involving neural networks, the use of GPUs and CPUs can lead to increased cost expenditure as we have advanced data structures but without any use for them. Whereas TPUs have only domain specific hardwares implemented in it and hence is an effective solution for the cost.\n",
        "\n",
        "3. Meeting real-time demands:\n",
        "\n",
        "People expect the response from any computer system to deliver without much response time by reducing the time taken for inferences for which the TPUs serves as a better purpose as they help to reduce the latency by minimizing the computations involved for the inference. They convert the large floating point numbers into 8 bit numbers and thereby reducing the time taken for inferring the output. But the accuracy is ensured by training the models with huge data sets without any quantization to ensure high level of accuracy."
      ],
      "metadata": {
        "id": "9O7k2DbXcNp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.3 Technical Deep Dive (15 Points):\n",
        "- Describe the architecture of the TPU. How is it optimized for machine learning workloads?\n",
        "- How does the memory hierarchy of the TPU differ from traditional processors, and why is this significant for tensor computations?\n",
        "- What are systolic arrays, and why are they used in TPUs?"
      ],
      "metadata": {
        "id": "PnzcxvhWckY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.3:"
      ],
      "metadata": {
        "id": "sv3rFNjpcuID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.4 Evaluation (25 Points):\n",
        "- How does the TPU's performance compare to contemporary CPUs and GPUs for machine learning tasks?\n",
        "- What benchmarks or workloads were used to evaluate the TPU's performance in the datacenter?\n",
        "- Discuss the TPU's performance per watt. Why is energy efficiency crucial in datacenter environments?\n",
        "- What types of machine learning models and tasks are best suited for TPUs?\n",
        "- How have TPUs impacted the training times of large-scale models at Google?"
      ],
      "metadata": {
        "id": "HRBvFutTc2uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.4:"
      ],
      "metadata": {
        "id": "xKUL8nhTdNLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.5 Contextual Understanding (10 Points):\n",
        "- What are some of the challenges faced in deploying TPUs in datacenters?\n",
        "- Are there specific machine learning tasks or models that TPUs might struggle with compared to other hardware?\n",
        "\n"
      ],
      "metadata": {
        "id": "Fp_FV2bzdV4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.5:"
      ],
      "metadata": {
        "id": "OvpxYhvNdg18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.6 Discussion and Critique (10 points):\n",
        "- What are the strengths and weaknesses of the paper's methodology and analysis?\n",
        "- Are there any potential biases or assumptions in the paper that you disagree with or find questionable?\n"
      ],
      "metadata": {
        "id": "cxUpnGmtdjfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.6:"
      ],
      "metadata": {
        "id": "cjAQy1qLdvZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.7 Reflection (10 Points):\n",
        "- How do TPUs fit into the larger trend of custom hardware accelerators for machine learning, such as FPGAs and ASICs?\n",
        "\n",
        "- Discuss the trade-offs between general-purpose hardware (like CPUs) and specialized hardware (like TPUs) in the context of evolving machine learning workloads.\n"
      ],
      "metadata": {
        "id": "hSMCnPg8d_0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.7:"
      ],
      "metadata": {
        "id": "nBtgEgPXeNR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Turn in your reading assignment by saving this answer sheet back to the Github repository."
      ],
      "metadata": {
        "id": "mnRyd9Iie6Dz"
      }
    }
  ]
}