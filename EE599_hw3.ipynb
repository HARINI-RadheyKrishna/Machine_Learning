{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HARINI-RadheyKrishna/Machine_Learning/blob/master/EE599_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PulVw_da4GML"
      },
      "source": [
        "# HW3 - EE599 Systems for Machine Learning, Fall 2023\n",
        "University of Southern California\n",
        "\n",
        "Instructors: Arash Saifhashemi, Murali Annavaram\n",
        "\n",
        "In this homework assignment, we will ask you to use various methods to implement convolution operation, and then measure and analyze the performance of each method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG26EClp5nEq"
      },
      "source": [
        "## Prepare your Google Drive\n",
        "- Download `ML_Systems_HW3` zip file from GitHub and unzip the it (you may need to rename the unzipped folder).\n",
        "- Upload unzipped folder to ``My Drive`` in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "02VQPV6q4Cav",
        "outputId": "f103fc3c-4870-4b59-aaad-b9ee381e991f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/ML_Systems_HW3/src')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITQeV_DO755_"
      },
      "source": [
        "## Verify that you are in the correct working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "m2Y1rLNv7434",
        "outputId": "0808c971-a487-432e-ea28-f08f5b0f22f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML_Systems_HW3/src\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dioEAKJm6BUN"
      },
      "source": [
        "## Create a folder named `build` under `ML_Systems_HW3/src`, which will be used to store executable files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XemyfZFZ6BUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a3ab373-141c-451e-dd86-449a808a9089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘build’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "TcEAwSWG6wSi",
        "outputId": "49ace51f-e273-4377-f218-b6e54899d69a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled q1_conv2d_naive.cc successfully!\n",
            "Compiled q2_conv2d_toeplitz.cc successfully!\n",
            "Compiled q3_conv2d_toeplitz_transB.cc successfully!\n",
            "Compiled q4_conv2d_toeplitz_avx.cc successfully!\n",
            "Compiled q5_conv2d_toeplitz_avx_openmp.cc successfully!\n",
            "Compiled q6_conv2d_toeplitz_blas.cc successfully!\n",
            "All files compiled successfully!\n"
          ]
        }
      ],
      "source": [
        "!bash compile.csh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "a0k8aaYu6zXv",
        "outputId": "6e6d7c22-5c12-4f54-f616-42d316200169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running q1_conv2d_naive ...\n",
            "Virtual Memory (KB): 16716\n",
            "temp: 0\n",
            "Time taken by function: 19174 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q2_conv2d_toeplitz ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 38754 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q3_conv2d_toeplitz_transB ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 13692 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q4_conv2d_toeplitz_avx ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 34927 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q5_conv2d_toeplitz_avx_openmp ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by 2 threaded core: 11969 milliseconds\n",
            "Time taken by 4 threaded core: 11160 milliseconds\n",
            "Time taken by 8 threaded core: 10985 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q6_conv2d_toeplitz_blas ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 92 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "!bash run.csh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Jeis0Q6BUO"
      },
      "source": [
        "## Compile and run your code:\n",
        "* To compile your C++ code, run command `!bash compile.csh`\n",
        "* To run your executable code, run command `!bash run.csh`\n",
        "* Check those csh files and modify accordingly when testing your code.\n",
        "* You can write and test your code on your local machine but make sure you can compile and run them on Colab. Also you should report the performance measured from Colab enverionment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNu5C22Q6BUO"
      },
      "source": [
        "## Write code and answer all questions in this notebook.\n",
        "Note that to measure the performance of each code, we want you to flush your cache. All the template files provide code that flush caches, but we need you to find the cache size of your system. Use the command below to display information about your CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OzO0J8J6BUO",
        "outputId": "bc32fc5d-10d1-49ec-ccf0-fe335e86dcc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:            x86_64\n",
            "  CPU op-mode(s):        32-bit, 64-bit\n",
            "  Address sizes:         46 bits physical, 48 bits virtual\n",
            "  Byte Order:            Little Endian\n",
            "CPU(s):                  2\n",
            "  On-line CPU(s) list:   0,1\n",
            "Vendor ID:               GenuineIntel\n",
            "  Model name:            Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:          6\n",
            "    Model:               79\n",
            "    Thread(s) per core:  2\n",
            "    Core(s) per socket:  1\n",
            "    Socket(s):           1\n",
            "    Stepping:            0\n",
            "    BogoMIPS:            4399.99\n",
            "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mc\n",
            "                         a cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscal\n",
            "                         l nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopo\n",
            "                         logy nonstop_tsc cpuid tsc_known_freq pni pclmulqdq sss\n",
            "                         e3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes \n",
            "                         xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefe\n",
            "                         tch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_ad\n",
            "                         just bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed ad\n",
            "                         x smap xsaveopt arat md_clear arch_capabilities\n",
            "Virtualization features: \n",
            "  Hypervisor vendor:     KVM\n",
            "  Virtualization type:   full\n",
            "Caches (sum of all):     \n",
            "  L1d:                   32 KiB (1 instance)\n",
            "  L1i:                   32 KiB (1 instance)\n",
            "  L2:                    256 KiB (1 instance)\n",
            "  L3:                    55 MiB (1 instance)\n",
            "NUMA:                    \n",
            "  NUMA node(s):          1\n",
            "  NUMA node0 CPU(s):     0,1\n",
            "Vulnerabilities:         \n",
            "  Itlb multihit:         Not affected\n",
            "  L1tf:                  Mitigation; PTE Inversion\n",
            "  Mds:                   Vulnerable; SMT Host state unknown\n",
            "  Meltdown:              Vulnerable\n",
            "  Mmio stale data:       Vulnerable\n",
            "  Retbleed:              Vulnerable\n",
            "  Spec store bypass:     Vulnerable\n",
            "  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy ba\n",
            "                         rriers only; no swapgs barriers\n",
            "  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBR\n",
            "                         S: Not affected\n",
            "  Srbds:                 Not affected\n",
            "  Tsx async abort:       Vulnerable\n"
          ]
        }
      ],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cache sizes are:\n",
        "\n",
        "    L1d:                   32 KiB (1 instance)\n",
        "    L1i:                   32 KiB (1 instance)\n",
        "    L2:                    256 KiB (1 instance)\n",
        "    L3:                    55 MiB (1 instance)"
      ],
      "metadata": {
        "id": "4Im77IvVs0rH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hk0XSjP9_n3"
      },
      "source": [
        "## Q1\n",
        "Implement 2D Convolution in the ``q1_conv2d_naive.cc`` using nested for loops. Assume batch size = 1, no padding and stride = 1. Check `util.h` file and understand what each function does. Use the micro `INDEX_4D_TO_1D` to help convert 4d index to 1d index. Measure and report runtime  (in milliseconds) and memory usage (in KB). Manually calculate memory usage and report. Does your calculation match with the measurement?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Memory Usage = (weightSize + inputSize + outputSize) * 4 bytes (for float or integer both)\n",
        "\n",
        "= (128*128*3*3 + 128*128*128 + 128*126*126) * 4\n",
        "\n",
        "= 17106944/1024 KB\n",
        "\n",
        "= 16706 KB (Actual: 16716 KB)"
      ],
      "metadata": {
        "id": "HafLEKA_nDC0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBXb2fV_-YO7"
      },
      "source": [
        "## Q2\n",
        "Use Img2col algorithm to convert the input matrix and kernel matrix to toeplitz form in file ``q2_conv2d_toeplitz.cc``. Interpret input toeplitz matrix and kernel toeplitz matrix as 2d matrix, and store both of them in row major. Use nested for loops to perform matrix multiplication in `matMul` function and call it in `main` function . There is another micro `INDEX_2D_TO_1D` that helps convert 2d index to 1d index. Measure and report runtime and memory usage. Manually calculate memory usage and report. Does your calculation match with the measurement?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual Memory Calculation:\n",
        "\n",
        "(output_p + output_q + output_c + outputToeplitzRows + outputToeplitzCols + outputToeplitzSize + outputs + inputToeplitzRows + inputToeplitzols + topleitzInput + weightTopleitzRows + weightTopleitzCols + topleitzWeight) * 4\n",
        "\n",
        "((126 × 2) + (128 × 3) + (126 × 126) + (128 × 126 × 126) + (128 × 3 × 3) + (128 × 3 × 3 × 126 × 126) + (128 × 128 × 3 × 3)) * 4\n",
        "\n",
        "= 81945600/1024\n",
        "\n",
        "= 80025 KB (Observed = 77964 KB)"
      ],
      "metadata": {
        "id": "PmsfDKZTrxZq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjmFTWrK_FJU"
      },
      "source": [
        "## Q3\n",
        "For `q3_conv2d_toeplitz_tranB.cc`, repeat procedures in Q2, but store kernel toeplitz matrix in column major and modify `matMul` function accordingly. Measure and report the runtime and memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(output_p + output_q + output_c + output_row + output_col + output + opSize + newinput_h + newinput_w + topinput + newweight_r + newweight_s + topweight) * 4\n",
        "\n",
        "= (128 + 126 + 126 + 128 + (126 * 126) + (128*126*126*2) + (128*3*3) + (126*126) + (128*3*3*126*126) + (128*3*3) + 128 + (128*3*3*128)) * 4\n",
        "\n",
        "= 82013712/1024\n",
        "\n",
        "= 80091.515 KB (Observed 77964 KB)"
      ],
      "metadata": {
        "id": "l_YN8tAu1IiA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5SaluD5_ydp"
      },
      "source": [
        "## Q4\n",
        "For ``q4_conv2d_toeplitz_avx.cc``, use Intel AVX (Advanced Vector Extensions) instruction set to perform matmul operation. Intel AVX instructions are Single Instruction Multiple Data (SIMD) instructions that can process 8 floating-point operands in a single instruction. Store input toeplitz matrix in row major and kernel toeplitz matrix in column major. An example of using Intel AVX is given in file ``examples/example_vectorsum_simd.cc``. Measure and report runtime and memory usage.\n",
        "\n",
        "Hint 1: Use `_mm256_add_ps` and `_mm256_mul_ps` instructions.\n",
        "\n",
        "Hint 2: If a vector is not divisible by 8, the remaining elements in the vector should not be processed by SIMD instruction. Instead, use normal scalar operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqRyp0x8A99J"
      },
      "source": [
        "## Q5\n",
        "\n",
        "### Part 1\n",
        "In file ``q5_conv2d_toeplitz_avx_openmp.cc``, futher optimize the AVX matmul operation using ``OpenMP`` library, which enables multi-threaded parallel computing automatically through a simple and flexible interface. An example of using ``OpenMP`` is given in file ``examples/example_vectorsum_simd_omd.cc``. Run the code with different number of threads. Measure and report the runtime for number of threads = [2, 4, 8].\n",
        "\n",
        "\n",
        "### Part 2 (Optional - No Credit)\n",
        "\n",
        "In file ``q5_optional_conv2d_toeplitz_avx_multi_thread.cc``, instead of using `OpenMP`, use the C++ standard `<thread>` library to implement multi-threaded AVX matmul operation. You can refer to [this video](https://youtu.be/3aqxaZsvn80?si=1QEE580e2vLmrqPO) to learn about multi threading in C++.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part1\n",
        "\n",
        "Runtime for 2 threaded core = 11810 ms\n",
        "\n",
        "Runtime for 4 threaded core = 14036 ms\n",
        "\n",
        "Runtime for 8 threaded core = 12113 ms"
      ],
      "metadata": {
        "id": "FroTolaZ3UOC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW-_R8gm6BUQ"
      },
      "source": [
        "## Q6\n",
        "\n",
        "In file ``q6_conv2d_toeplitz_blas.cc``, use `BLAS` library to implement matmul operation. You can decide the storage format for input and kernel toeplitz matrices, and make sure you set input arguments of `cblas_sgemm` accordingly. An example is given in file ``examples/example_matmul_blas.cc``. Search online document of `cblas_sgemm` API if you are unclear about the mearning of each of its input argument. Follow the example and and finish your own code. Measure and report runtime and memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVxmA8VB2n5"
      },
      "source": [
        "## Q7  \n",
        "\n",
        "### Part 1\n",
        "\n",
        "\n",
        "Analyze the performance differences between Q1-Q6. Explain what constitutes the performance difference between each implementations and why `BLAS` library is super fast.\n",
        "\n",
        "### Part 2: Using Google Benchmark (Optional - No Credit)\n",
        "As an optional practice, you can measure the runtime of each matrix calculation method more accurately using Google benchmark.\n",
        "\n",
        "A better way to measure performance of a funcion in C++ is to use Google Benchmark. You can refer to [this video](https://youtu.be/9VKR8u9odrA?si=xSInuzT5uMBOKAbP) to familiarize yourself with this package.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1 - Summary of the performances:**\n",
        "\n",
        "**Expected results:**\n",
        "\n",
        "**1. Memory usage**\n",
        "\n",
        "In terms of memory requirements the naive convolution has very minimal additional memory requirements.\n",
        "\n",
        "Memory requirements increase as we go with Topleitz based methods.\n",
        "\n",
        "But CBLAS is expected to have memory optimizations.\n",
        "\n",
        "**2. Runtime**\n",
        "\n",
        "The runtime is slowest for Naive convolution as it involves huge computations and hence longer runtimes.\n",
        "\n",
        "Topleitz based convolution provide improvements to the runtime.As they do not work on redundant convolutions.  \n",
        "\n",
        "Parallelism is exploited in AVX and OpenMP. Parallelization is improved in AVX by implementing vectorized computation.\n",
        "\n",
        "OpenMP further improves the runtime due to additional parallelism introduced by OpenMP.\n",
        "\n",
        "Hence they both are expected to produce more or less the same results.\n",
        "\n",
        "CBLAS uses highly optimized BLAS Library functions and hence the runtime is the fastest for this method.\n",
        "\n",
        "\n",
        "**Obtained results:**\n",
        "\n",
        "**1. Memory Usage**\n",
        "\n",
        "As expected the memory requirement is very minimal for naive convolution as expected with around 16KB. Naive convolution uses memory proportional to the size of input, output, and kernel tensors. It involves direct computation without additional memory overhead. That is why the memory usage is very minimal.\n",
        "\n",
        "Convolution using Toeplitz Matrix in Row-Major Order and Column-Major order requires additional memory for the Toeplitz matrix. The memory overhead is proportional to the input size and kernel size.\n",
        "\n",
        "\n",
        "Convolution using Topleitz matrix with Intel AVX and with OpenMP also requires the same memory requirements as it also involves Topleitz matrices to convolve.\n",
        "\n",
        "\n",
        "CBLAS function has optimized routines hence it should have reduced memory usage. But if we are not using the highly optimized routines, then the memory requirement will be the same as Convolution involving Topleitz matrices.\n",
        "\n",
        "\n",
        "**2. Runtime:**\n",
        "\n",
        "The runtime for naive convolution should be the slowest and it is as expected.\n",
        "\n",
        "The convolution using Topleitz matrix for q2 and q3 should consume less than the naive convolution as they aim to not work on redundant convolutions, which is realized for q3. The reason for the slow runtime can be due to the implementation of row and col based multiplication for both input and weight Topleitz matrices.\n",
        "\n",
        "Convolution using Topleitz matrix using AVX should consume less time than q1, q2 and q3 but because of the huge memory requirements for the buffers, I suppose it is consuming much time for the calculations. This is the only deviation in the program from the expected values.\n",
        "\n",
        "The runtime of the matrix convolution using Topleitz matrix using AVX and advancing it with OpenMP has improved from q1, q2 and q3 as expected as it aims to improve the runtime by further exploiting parallelism.\n",
        "\n",
        "The runtime for implementation of convolution using cBLAS should be very minimal as it uses advanced algorithms for memory optimizations and therby reducing the runtime drastically below the rest of the optimization methods.\n"
      ],
      "metadata": {
        "id": "EhaROnZf_Pw_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m7NCnmR6BUQ"
      },
      "source": [
        "## Upload files to GitHub\n",
        "Make sure upload your final C++ code and this IPython notebook to GitHub Repo either mannully or through git commands."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}