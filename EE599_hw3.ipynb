{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HARINI-RadheyKrishna/Machine_Learning/blob/master/EE599_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PulVw_da4GML"
      },
      "source": [
        "# HW3 - EE599 Systems for Machine Learning, Fall 2023\n",
        "University of Southern California\n",
        "\n",
        "Instructors: Arash Saifhashemi, Murali Annavaram\n",
        "\n",
        "In this homework assignment, we will ask you to use various methods to implement convolution operation, and then measure and analyze the performance of each method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG26EClp5nEq"
      },
      "source": [
        "## Prepare your Google Drive\n",
        "- Download `ML_Systems_HW3` zip file from GitHub and unzip the it (you may need to rename the unzipped folder).\n",
        "- Upload unzipped folder to ``My Drive`` in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "02VQPV6q4Cav",
        "outputId": "7f101a70-7ee0-4dd3-f1b7-e88faccfebf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/ML_Systems_HW3/src')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITQeV_DO755_"
      },
      "source": [
        "## Verify that you are in the correct working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "m2Y1rLNv7434",
        "outputId": "e0b1e71e-2407-40fa-b4ef-7dd1799e9b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML_Systems_HW3/src\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dioEAKJm6BUN"
      },
      "source": [
        "## Create a folder named `build` under `ML_Systems_HW3/src`, which will be used to store executable files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "XemyfZFZ6BUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e37de58-53f3-4de9-af7a-5907c257e473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘build’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "TcEAwSWG6wSi",
        "outputId": "d7ea8f1c-ca31-4fdc-d334-1c9ee9ef1f0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled q1_conv2d_naive.cc successfully!\n",
            "Compiled q2_conv2d_toeplitz.cc successfully!\n",
            "Compiled q3_conv2d_toeplitz_transB.cc successfully!\n",
            "Compiled q4_conv2d_toeplitz_avx.cc successfully!\n",
            "Compiled q5_conv2d_toeplitz_avx_openmp.cc successfully!\n",
            "Compiled q6_conv2d_toeplitz_blas.cc successfully!\n",
            "All files compiled successfully!\n"
          ]
        }
      ],
      "source": [
        "!bash compile.csh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "a0k8aaYu6zXv",
        "outputId": "33bc932d-152a-4b38-9778-9f36c441efb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running q1_conv2d_naive ...\n",
            "Virtual Memory (KB): 16716\n",
            "temp: 0\n",
            "Time taken by function: 19063 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q2_conv2d_toeplitz ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 32989 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q3_conv2d_toeplitz_transB ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 13526 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q4_conv2d_toeplitz_avx ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 35896 milliseconds\n",
            "Sum of all outputs: 47243571200\n",
            "-------------------------------------------\n",
            "Running q5_conv2d_toeplitz_avx_openmp ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "Time taken by function: 167703 milliseconds\n",
            "Sum of all outputs: 0\n",
            "-------------------------------------------\n",
            "Running q6_conv2d_toeplitz_blas ...\n",
            "Virtual Memory (KB): 79964\n",
            "temp: 0\n",
            "terminate called after throwing an instance of 'std::invalid_argument'\n",
            "  what():  Matrix dimensions mismatch for multiplication\n",
            "run.csh: line 15: 157843 Aborted                 (core dumped) ./build/\"$output_name\"\n",
            "-------------------------------------------\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "!bash run.csh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Jeis0Q6BUO"
      },
      "source": [
        "## Compile and run your code:\n",
        "* To compile your C++ code, run command `!bash compile.csh`\n",
        "* To run your executable code, run command `!bash run.csh`\n",
        "* Check those csh files and modify accordingly when testing your code.\n",
        "* You can write and test your code on your local machine but make sure you can compile and run them on Colab. Also you should report the performance measured from Colab enverionment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNu5C22Q6BUO"
      },
      "source": [
        "## Write code and answer all questions in this notebook.\n",
        "Note that to measure the performance of each code, we want you to flush your cache. All the template files provide code that flush caches, but we need you to find the cache size of your system. Use the command below to display information about your CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OzO0J8J6BUO",
        "outputId": "bc32fc5d-10d1-49ec-ccf0-fe335e86dcc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:            x86_64\n",
            "  CPU op-mode(s):        32-bit, 64-bit\n",
            "  Address sizes:         46 bits physical, 48 bits virtual\n",
            "  Byte Order:            Little Endian\n",
            "CPU(s):                  2\n",
            "  On-line CPU(s) list:   0,1\n",
            "Vendor ID:               GenuineIntel\n",
            "  Model name:            Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:          6\n",
            "    Model:               79\n",
            "    Thread(s) per core:  2\n",
            "    Core(s) per socket:  1\n",
            "    Socket(s):           1\n",
            "    Stepping:            0\n",
            "    BogoMIPS:            4399.99\n",
            "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mc\n",
            "                         a cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscal\n",
            "                         l nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopo\n",
            "                         logy nonstop_tsc cpuid tsc_known_freq pni pclmulqdq sss\n",
            "                         e3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes \n",
            "                         xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefe\n",
            "                         tch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_ad\n",
            "                         just bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed ad\n",
            "                         x smap xsaveopt arat md_clear arch_capabilities\n",
            "Virtualization features: \n",
            "  Hypervisor vendor:     KVM\n",
            "  Virtualization type:   full\n",
            "Caches (sum of all):     \n",
            "  L1d:                   32 KiB (1 instance)\n",
            "  L1i:                   32 KiB (1 instance)\n",
            "  L2:                    256 KiB (1 instance)\n",
            "  L3:                    55 MiB (1 instance)\n",
            "NUMA:                    \n",
            "  NUMA node(s):          1\n",
            "  NUMA node0 CPU(s):     0,1\n",
            "Vulnerabilities:         \n",
            "  Itlb multihit:         Not affected\n",
            "  L1tf:                  Mitigation; PTE Inversion\n",
            "  Mds:                   Vulnerable; SMT Host state unknown\n",
            "  Meltdown:              Vulnerable\n",
            "  Mmio stale data:       Vulnerable\n",
            "  Retbleed:              Vulnerable\n",
            "  Spec store bypass:     Vulnerable\n",
            "  Spectre v1:            Vulnerable: __user pointer sanitization and usercopy ba\n",
            "                         rriers only; no swapgs barriers\n",
            "  Spectre v2:            Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eIBR\n",
            "                         S: Not affected\n",
            "  Srbds:                 Not affected\n",
            "  Tsx async abort:       Vulnerable\n"
          ]
        }
      ],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cache sizes are:\n",
        "\n",
        "    L1d:                   32 KiB (1 instance)\n",
        "    L1i:                   32 KiB (1 instance)\n",
        "    L2:                    256 KiB (1 instance)\n",
        "    L3:                    55 MiB (1 instance)"
      ],
      "metadata": {
        "id": "4Im77IvVs0rH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hk0XSjP9_n3"
      },
      "source": [
        "## Q1\n",
        "Implement 2D Convolution in the ``q1_conv2d_naive.cc`` using nested for loops. Assume batch size = 1, no padding and stride = 1. Check `util.h` file and understand what each function does. Use the micro `INDEX_4D_TO_1D` to help convert 4d index to 1d index. Measure and report runtime  (in milliseconds) and memory usage (in KB). Manually calculate memory usage and report. Does your calculation match with the measurement?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Memory Usage = (weightSize + inputSize + outputSize) * 4 bytes (for float or integer both)\n",
        "\n",
        "= (128*128*3*3 + 128*128*128 + 128*126*126) * 4\n",
        "= 17106944/1024 KB\n",
        "= 16706 KB (Actual: 16716 KB)"
      ],
      "metadata": {
        "id": "HafLEKA_nDC0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBXb2fV_-YO7"
      },
      "source": [
        "## Q2\n",
        "Use Img2col algorithm to convert the input matrix and kernel matrix to toeplitz form in file ``q2_conv2d_toeplitz.cc``. Interpret input toeplitz matrix and kernel toeplitz matrix as 2d matrix, and store both of them in row major. Use nested for loops to perform matrix multiplication in `matMul` function and call it in `main` function . There is another micro `INDEX_2D_TO_1D` that helps convert 2d index to 1d index. Measure and report runtime and memory usage. Manually calculate memory usage and report. Does your calculation match with the measurement?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual Memory Calculation:\n",
        "\n",
        "(output_p + output_q + output_c + outputToeplitzRows + outputToeplitzCols + outputToeplitzSize + outputs + inputToeplitzRows + inputToeplitzols + topleitzInput + weightTopleitzRows + weightTopleitzCols + topleitzWeight) * 4\n",
        "\n",
        "((126 × 2) + (128 × 3) + (126 × 126) + (128 × 126 × 126 × 2) + (128 × 3 × 3) + (128 × 3 × 3 × 126 × 126) + (128 × 128 × 3 × 3)) * 4\n",
        "\n",
        "= 90074112/1024\n",
        "\n",
        "= 87963 KB (Observed = 77964 KB)"
      ],
      "metadata": {
        "id": "PmsfDKZTrxZq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjmFTWrK_FJU"
      },
      "source": [
        "## Q3\n",
        "For `q3_conv2d_toeplitz_tranB.cc`, repeat procedures in Q2, but store kernel toeplitz matrix in column major and modify `matMul` function accordingly. Measure and report the runtime and memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(output_p + output_q + output_c + output_row + output_col + output + opSize + newinput_h + newinput_w + topinput + newweight_r + newweight_s + topweight) * 4\n",
        "\n",
        "= (128 + 126 + 126 + 128 + (126 * 126) + (128*126*126*2) + (128*3*3) + (126*126) + (128*3*3*126*126) + (128*3*3) + 128 + (128*3*3*128)) * 4\n",
        "\n",
        "= 90142224/1024\n",
        "\n",
        "= 88029.515 KB (Observed 77964 KB)"
      ],
      "metadata": {
        "id": "l_YN8tAu1IiA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5SaluD5_ydp"
      },
      "source": [
        "## Q4\n",
        "For ``q4_conv2d_toeplitz_avx.cc``, use Intel AVX (Advanced Vector Extensions) instruction set to perform matmul operation. Intel AVX instructions are Single Instruction Multiple Data (SIMD) instructions that can process 8 floating-point operands in a single instruction. Store input toeplitz matrix in row major and kernel toeplitz matrix in column major. An example of using Intel AVX is given in file ``examples/example_vectorsum_simd.cc``. Measure and report runtime and memory usage.\n",
        "\n",
        "Hint 1: Use `_mm256_add_ps` and `_mm256_mul_ps` instructions.\n",
        "\n",
        "Hint 2: If a vector is not divisible by 8, the remaining elements in the vector should not be processed by SIMD instruction. Instead, use normal scalar operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqRyp0x8A99J"
      },
      "source": [
        "## Q5\n",
        "\n",
        "### Part 1\n",
        "In file ``q5_conv2d_toeplitz_avx_openmp.cc``, futher optimize the AVX matmul operation using ``OpenMP`` library, which enables multi-threaded parallel computing automatically through a simple and flexible interface. An example of using ``OpenMP`` is given in file ``examples/example_vectorsum_simd_omd.cc``. Run the code with different number of threads. Measure and report the runtime for number of threads = [2, 4, 8].\n",
        "\n",
        "\n",
        "### Part 2 (Optional - No Credit)\n",
        "\n",
        "In file ``q5_optional_conv2d_toeplitz_avx_multi_thread.cc``, instead of using `OpenMP`, use the C++ standard `<thread>` library to implement multi-threaded AVX matmul operation. You can refer to [this video](https://youtu.be/3aqxaZsvn80?si=1QEE580e2vLmrqPO) to learn about multi threading in C++.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runtime for 2 threaded core =\n",
        "\n",
        "Runtime for 4 threaded core =\n",
        "\n",
        "Runtime for 8 threaded core ="
      ],
      "metadata": {
        "id": "FroTolaZ3UOC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW-_R8gm6BUQ"
      },
      "source": [
        "## Q6\n",
        "\n",
        "In file ``q6_conv2d_toeplitz_blas.cc``, use `BLAS` library to implement matmul operation. You can decide the storage format for input and kernel toeplitz matrices, and make sure you set input arguments of `cblas_sgemm` accordingly. An example is given in file ``examples/example_matmul_blas.cc``. Search online document of `cblas_sgemm` API if you are unclear about the mearning of each of its input argument. Follow the example and and finish your own code. Measure and report runtime and memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVxmA8VB2n5"
      },
      "source": [
        "## Q7  \n",
        "\n",
        "### Part 1\n",
        "\n",
        "\n",
        "Analyze the performance differences between Q1-Q6. Explain what constitutes the performance difference between each implementations and why `BLAS` library is super fast.\n",
        "\n",
        "### Part 2: Using Google Benchmark (Optional - No Credit)\n",
        "As an optional practice, you can measure the runtime of each matrix calculation method more accurately using Google benchmark.\n",
        "\n",
        "A better way to measure performance of a funcion in C++ is to use Google Benchmark. You can refer to [this video](https://youtu.be/9VKR8u9odrA?si=xSInuzT5uMBOKAbP) to familiarize yourself with this package.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m7NCnmR6BUQ"
      },
      "source": [
        "## Upload files to GitHub\n",
        "Make sure upload your final C++ code and this IPython notebook to GitHub Repo either mannully or through git commands."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}